{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:51:20.688518Z","iopub.execute_input":"2023-11-05T15:51:20.688932Z","iopub.status.idle":"2023-11-05T15:51:23.755216Z","shell.execute_reply.started":"2023-11-05T15:51:20.688896Z","shell.execute_reply":"2023-11-05T15:51:23.753951Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading the model","metadata":{}},{"cell_type":"code","source":"from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast\nmodel = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\ntokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:51:23.757253Z","iopub.execute_input":"2023-11-05T15:51:23.757811Z","iopub.status.idle":"2023-11-05T15:53:02.204406Z","shell.execute_reply.started":"2023-11-05T15:51:23.757770Z","shell.execute_reply":"2023-11-05T15:53:02.203077Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7686eab1750e418498866b985846aee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63dd9863b4b340dbb1ab61164a0b8b92"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218c01bf4d6b418abf6702becbbb557e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a2dd1e8c914890a9c9c7413c83e918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa08bd97122443c9cce597cf3685a07"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Examples of initial paraphrasing","metadata":{}},{"cell_type":"code","source":"tokenizer.batch_decode(\n    model.generate(\n        tokenizer.encode(\"At least one of you Dunham cunts are gonna pay for my fucking boy.\", return_tensors='pt'),\n        temperature=1.0\n    ),\n    skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:53:16.026144Z","iopub.execute_input":"2023-11-05T15:53:16.026581Z","iopub.status.idle":"2023-11-05T15:53:22.016931Z","shell.execute_reply.started":"2023-11-05T15:53:16.026550Z","shell.execute_reply":"2023-11-05T15:53:22.013392Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['One of you will pay for my boy.']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.batch_decode(\n    model.generate(\n        tokenizer.encode(\"you can't do both of me crazy!\", return_tensors='pt'),\n        temperature=1.0\n    ),\n    skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:50:38.629734Z","iopub.execute_input":"2023-11-05T16:50:38.630886Z","iopub.status.idle":"2023-11-05T16:50:42.265813Z","shell.execute_reply.started":"2023-11-05T16:50:38.630835Z","shell.execute_reply":"2023-11-05T16:50:42.264636Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[\"You can't do both of me crazy!\"]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.batch_decode(\n    model.generate(\n        tokenizer.encode(\"He is shit.\", return_tensors='pt'),\n        temperature=1.0\n    ),\n    skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:55:02.202285Z","iopub.execute_input":"2023-11-05T15:55:02.202806Z","iopub.status.idle":"2023-11-05T15:55:04.570995Z","shell.execute_reply.started":"2023-11-05T15:55:02.202739Z","shell.execute_reply":"2023-11-05T15:55:04.569847Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['He is not good.']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dataset building","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nclass MyDataset(Dataset):\n    def __init__(self):\n        self.data = pd.read_csv(\n            os.path.join(os.getcwd(), '..', 'input', 'testing-data', 'test.csv'),\n            sep='\\t'\n        )\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return [self.data['toxic_sentence'][idx], self.data['neutral_sentence'][idx]]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:20:01.187916Z","iopub.execute_input":"2023-11-05T16:20:01.188359Z","iopub.status.idle":"2023-11-05T16:20:01.197875Z","shell.execute_reply.started":"2023-11-05T16:20:01.188326Z","shell.execute_reply":"2023-11-05T16:20:01.196660Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset = MyDataset()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:20:04.041875Z","iopub.execute_input":"2023-11-05T16:20:04.042258Z","iopub.status.idle":"2023-11-05T16:20:04.714480Z","shell.execute_reply.started":"2023-11-05T16:20:04.042228Z","shell.execute_reply":"2023-11-05T16:20:04.713333Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    batch = np.array(batch)\n    toxic, neutral = batch[:, 0], batch[:, 1]\n    toxic = tokenizer.batch_encode_plus(toxic.tolist(), add_special_tokens=True,\n                                        padding='max_length', return_tensors='pt')['input_ids']\n    \n    model_gen = model.generate(toxic, temperature=1.0)\n    \n    neutral = tokenizer.batch_encode_plus(neutral.tolist(), add_special_tokens=True,\n                                          truncation=True,\n                                          padding='max_length', return_tensors='pt',\n                                         max_length=len(model_gen[0]))['input_ids']\n    return toxic, neutral, model_gen\n\ntest_loader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T18:22:58.055522Z","iopub.execute_input":"2023-11-05T18:22:58.055997Z","iopub.status.idle":"2023-11-05T18:22:58.065095Z","shell.execute_reply.started":"2023-11-05T18:22:58.055958Z","shell.execute_reply":"2023-11-05T18:22:58.064020Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"def train_loop(model, dataloader, num_epoch=1, smaple_size=2):\n    model.train()\n    pbar = tqdm(enumerate(dataloader), total=smaple_size)\n    for epoch in range(num_epoch):\n        losses = []\n        for idx, batch in pbar:\n            if idx == smaple_size:\n                break\n            \n            toxic, neutral, model_gen = batch\n            loss = model(input_ids=toxic, decoder_input_ids=model_gen, labels=neutral)[0]\n            losses.append(loss.item())\n            loss.backward()\n            \n            pbar.set_postfix({\n                'Epoch': f'{epoch + 1}/{num_epoch}',\n                'Batch': f'{idx + 1}/{smaple_size}',\n                'Loss': f\"{sum(losses) / len(losses)}\"\n            })\n    model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:45:48.327394Z","iopub.execute_input":"2023-11-05T16:45:48.327853Z","iopub.status.idle":"2023-11-05T16:45:48.337277Z","shell.execute_reply.started":"2023-11-05T16:45:48.327809Z","shell.execute_reply":"2023-11-05T16:45:48.336231Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_loop(model, test_loader, smaple_size=10)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:47:05.786828Z","iopub.execute_input":"2023-11-05T16:47:05.787254Z","iopub.status.idle":"2023-11-05T16:50:13.328938Z","shell.execute_reply.started":"2023-11-05T16:47:05.787219Z","shell.execute_reply":"2023-11-05T16:50:13.328098Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [03:07<00:00, 18.75s/it, Epoch=1/1, Batch=10/10, Loss=9.836823177337646]\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T14:51:43.692336Z","iopub.execute_input":"2023-11-05T14:51:43.692725Z","iopub.status.idle":"2023-11-05T14:51:43.702226Z","shell.execute_reply.started":"2023-11-05T14:51:43.692692Z","shell.execute_reply":"2023-11-05T14:51:43.700779Z"},"trusted":true},"execution_count":261,"outputs":[{"execution_count":261,"output_type":"execute_result","data":{"text/plain":"[\"you can't do both of me crazy!\", \"You can't fool me twice!\"]"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:14:35.677221Z","iopub.execute_input":"2023-11-05T17:14:35.677668Z","iopub.status.idle":"2023-11-05T17:14:40.934380Z","shell.execute_reply.started":"2023-11-05T17:14:35.677616Z","shell.execute_reply":"2023-11-05T17:14:40.933428Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"return_model = PegasusForConditionalGeneration.from_pretrained('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:15:46.174069Z","iopub.execute_input":"2023-11-05T17:15:46.174476Z","iopub.status.idle":"2023-11-05T17:15:59.253688Z","shell.execute_reply.started":"2023-11-05T17:15:46.174446Z","shell.execute_reply":"2023-11-05T17:15:59.252269Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"dataset[10][0], tokenizer.batch_decode(\n    return_model.generate(\n        tokenizer.encode(dataset[10][0], return_tensors='pt'),\n        temperature=1.0\n    ),\n    skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T18:24:30.146376Z","iopub.execute_input":"2023-11-05T18:24:30.146806Z","iopub.status.idle":"2023-11-05T18:24:34.726251Z","shell.execute_reply.started":"2023-11-05T18:24:30.146770Z","shell.execute_reply":"2023-11-05T18:24:34.725125Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"('Vega must have been killed after the judge threatened us.',\n ['The judge threatened us.'])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Downloading the model into zip to download in localy","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:22:10.676974Z","iopub.execute_input":"2023-11-05T17:22:10.677798Z","iopub.status.idle":"2023-11-05T17:22:10.687338Z","shell.execute_reply.started":"2023-11-05T17:22:10.677755Z","shell.execute_reply":"2023-11-05T17:22:10.686009Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working/model.h5', 'model')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:22:37.880761Z","iopub.execute_input":"2023-11-05T17:22:37.881221Z","iopub.status.idle":"2023-11-05T17:24:57.684822Z","shell.execute_reply.started":"2023-11-05T17:22:37.881185Z","shell.execute_reply":"2023-11-05T17:24:57.683901Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model.zip","text/html":"<a href='model.zip' target='_blank'>model.zip</a><br>"},"metadata":{}}]}]}